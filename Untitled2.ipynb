{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2JDt/633BhjDAZTLJ2wZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drluth/Automatisation-analyse-cv/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkiCJOw2H8Tm"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "#Charger les CV\n",
        "def load_cv_texts(folder):\n",
        "    cvs = {}\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".pdf\"):\n",
        "            cvs[file] = extract_text_pdf(os.path.join(folder, file))\n",
        "        elif file.endswith(\".docx\"):\n",
        "            cvs[file] = extract_text_docx(os.path.join(folder, file))\n",
        "    return cvs\n",
        "\n",
        "\n",
        "#Extraire les information d'un word\n",
        "def extract_text_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \" \".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "# Extraire les information d'un pdf\n",
        "def extract_text_from_pdf(path):\n",
        "  doc = fitz.open(path)\n",
        "  text = \"\"\n",
        "  for page in doc:\n",
        "    text += page.get_text()\n",
        "  return text\n",
        "\n",
        "## prétraitement du text\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "def clean_text(text):\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  text = re.sub(r'[^a-zA-Z0-9 ]', '', text)  # Supprime les caractères spéciaux\n",
        "  text = text.lower()\n",
        "  doc = nlp(text)\n",
        "  return \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
        "\n",
        "\n",
        "# Extraction des information clés\n",
        "def extract_info(text):\n",
        "    doc = nlp(text)\n",
        "    name = \"\"\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":\n",
        "            name = ent.text\n",
        "            break\n",
        "    skills = [token.text for token in doc if token.pos_ == \"NOUN\" and token.text.lower() not in nlp.Defaults.stop_words]\n",
        "    return {\"name\": name, \"skills\": skills[:10]}\n",
        "\n",
        "#Matching CV <-> Offre d'emploi\n",
        "def calculate_similarity(cv_text, job_description):\n",
        "    tfidf = TfidfVectorizer()\n",
        "    vectors = tfidf.fit_transform([cv_text, job_description])\n",
        "    return cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
        "\n",
        "\n",
        "#Générer un rapport\n",
        "def generate_report(results):\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"rapport_cv.csv\", index=False)\n",
        "\n",
        "\n",
        "job_desc_path = \"job_description.txt\"\n",
        "\n",
        "def execution()\n",
        "    cv_dir = \"data/cvs/\"\n",
        "    job_description = open(job_desc_path, 'r').read()\n",
        "    cvs = load_cv_texts(cv_dir)\n",
        "    results = []\n",
        "\n",
        "    for cv_file, raw_text in cvs.items():\n",
        "        clean_text = preprocess_text(raw_text)\n",
        "        infos = extract_info(clean_text)\n",
        "        score = match_cv_job(clean_text, job_description)\n",
        "        results.append({\"CV\": cv_file, \"Nom\": infos[\"name\"], \"Compétences\": infos[\"skills\"], \"Score\": score})\n",
        "    save_report(results)\n",
        "\n",
        "execution()"
      ]
    }
  ]
}